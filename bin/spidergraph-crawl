#!/usr/bin/env babel-node

import { graphql } from 'graphql'
import loadQueryStore from "../src/queryStore.js";
import Browser from "../src/browser";
import schema from "../src/schema";
// import {pubsub, CHANNEL} from "../src/pubsub";
import program from 'commander';
import { transports } from '../src/logger';
import request from 'request'

import { Observable } from "rxjs";
import { take, concatMap, expand, mergeMap } from "rxjs/operators";

// fully random by @BetonMAN
const shuffleArray = arr => (
  arr
    .map(a => [Math.random(), a])
    .sort((a, b) => a[0] - b[0])
    .map(a => a[1])
);


const browser = new Browser()

const fetch = async (urls, queryStore) => {
  const loader = browser.loader()
  const results = await Promise.all(urls.map(async url => {
    console.log({url})
    if (url === null) return []

    const page = await loader.load(url);
    const data = await Promise.all(queryStore.map(async (query) => {
      const pattern = new RegExp(query.config.match.url);
      if (!pattern.test(url)) return;

      const result = await graphql(schema, query.queryString, {}, {page: page}).then((result) => {
        return result
      })

      return {
        info: {
          query: query.queryName,
          url: url
        },
        data: result.data
      }
    }))
    page.close()
    return data
  }));

  return [].concat(...results).filter(n => n)
}

const scrape = async (urls) => {
  const { LISTING_PAGE_LIMIT, API_ENDPOINT } = process.env
  transports.console.level = 'info'
  const queryStore = await loadQueryStore(schema);
  await browser.init()
  const listCrawler = Observable.fromPromise(fetch(urls, queryStore))
    .pipe(
      expand(event => {
        const next = event.map(e => e.data.crawler.pagination.next);
        return Observable.fromPromise(fetch(next, queryStore))
      }
    ),
    take(parseInt(LISTING_PAGE_LIMIT)),

    concatMap(event => {
      const collections = event.map(e => e.data.crawler.collection)
      return shuffleArray([].concat(...collections))
    })
  )

  const throttled = listCrawler.pipe(
    mergeMap(event => {
      console.log('event url debugging', event)
      if (event === null) return Observable.empty();
      return Observable.fromPromise(fetch([event.url], queryStore))
    }, null, 1)
  );

  throttled.subscribe(property => {
    console.log(property)
    request({
        url: API_ENDPOINT,
        method: "POST",
        json: true,
        body: {payload: property[0]}
    }, function (error, response, body){
      console.log({error});
    });
  },
  (error) => { console.log('error', error)},
  async () => { await browser.close() });
}

const list = (val) => {
  return val.split(",");
}

program
  .arguments('<urls>')
  .action(async (urls) => (await scrape(list(urls))))
  .parse(process.argv);
